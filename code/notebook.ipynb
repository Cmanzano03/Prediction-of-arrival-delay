{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# Spark practical work\n",
    "### Melen Laclais, Carlos Manzano Izquierdo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d0fd87c592ef9d",
   "metadata": {},
   "source": [
    "## Load of training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3ced1f85aea866d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:06:50.838844293Z",
     "start_time": "2025-12-29T17:06:50.496445509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw flight data (2006-2007)... This may take a moment due to schema inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 146:============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total flights loaded: 14,595,137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, isnan\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Flight_Delay_EDA_Analysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load Training Data (2006 + 2007)\n",
    "print(\"Loading raw flight data (2006-2007)... This may take a moment due to schema inference...\")\n",
    "\n",
    "# We use inferSchema=True to see the actual data types Spark detects\n",
    "# We use nullValue=\"NA\" because the documentation states \"NA\" is used for nulls\n",
    "flights_raw = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"nullValue\", \"NA\") \\\n",
    "    .csv([\"../training_data/flight_data/2006.csv.bz2\", \"../training_data/flight_data/2007.csv.bz2\"])\n",
    "\n",
    "# Load auxiliary tables for inspection\n",
    "planes_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"nullValue\", \"NA\").csv(\"../training_data/flight_data/plane-data.csv\")\n",
    "airports_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"nullValue\", \"NA\").csv(\"../training_data/flight_data/airports.csv\")\n",
    "\n",
    "print(f\"Total flights loaded: {flights_raw.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca832b",
   "metadata": {},
   "source": [
    "## Dataset exploration, analysis and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d80a7",
   "metadata": {},
   "source": [
    "First, lets start by analyzing the schema of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "553c2629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inferred Schema ---\n",
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: integer (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: integer (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: integer (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- AirTime: integer (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiIn: integer (nullable = true)\n",
      " |-- TaxiOut: integer (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: integer (nullable = true)\n",
      " |-- WeatherDelay: integer (nullable = true)\n",
      " |-- NASDelay: integer (nullable = true)\n",
      " |-- SecurityDelay: integer (nullable = true)\n",
      " |-- LateAircraftDelay: integer (nullable = true)\n",
      "\n",
      "--- Data Sample (First 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Year",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Month",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "DayofMonth",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "DayOfWeek",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "DepTime",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "CRSDepTime",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "ArrTime",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "CRSArrTime",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "UniqueCarrier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "FlightNum",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "TailNum",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ActualElapsedTime",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "CRSElapsedTime",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "AirTime",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "ArrDelay",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "DepDelay",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Origin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Dest",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Distance",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "TaxiIn",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "TaxiOut",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Cancelled",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "CancellationCode",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Diverted",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "CarrierDelay",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "WeatherDelay",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "NASDelay",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "SecurityDelay",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "LateAircraftDelay",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "58975c16-b9f9-4adb-9cb0-651ed1c7e07f",
       "rows": [
        [
         "0",
         "2006",
         "1",
         "11",
         "3",
         "743",
         "745",
         "1024",
         "1018",
         "US",
         "343",
         "N657AW",
         "281",
         "273",
         "223",
         "6",
         "-2",
         "ATL",
         "PHX",
         "1587",
         "45",
         "13",
         "0",
         null,
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "2006",
         "1",
         "11",
         "3",
         "1053",
         "1053",
         "1313",
         "1318",
         "US",
         "613",
         "N834AW",
         "260",
         "265",
         "214",
         "-5",
         "0",
         "ATL",
         "PHX",
         "1587",
         "27",
         "19",
         "0",
         null,
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2",
         "2006",
         "1",
         "11",
         "3",
         "1915",
         "1915",
         "2110",
         "2133",
         "US",
         "617",
         "N605AW",
         "235",
         "258",
         "220",
         "-23",
         "0",
         "ATL",
         "PHX",
         "1587",
         "4",
         "11",
         "0",
         null,
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "2006",
         "1",
         "11",
         "3",
         "1753",
         "1755",
         "1925",
         "1933",
         "US",
         "300",
         "N312AW",
         "152",
         "158",
         "126",
         "-8",
         "-2",
         "AUS",
         "PHX",
         "872",
         "16",
         "10",
         "0",
         null,
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "4",
         "2006",
         "1",
         "11",
         "3",
         "824",
         "832",
         "1015",
         "1015",
         "US",
         "765",
         "N309AW",
         "171",
         "163",
         "132",
         "0",
         "-8",
         "AUS",
         "PHX",
         "872",
         "27",
         "12",
         "0",
         null,
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 29,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>743</td>\n",
       "      <td>745</td>\n",
       "      <td>1024</td>\n",
       "      <td>1018</td>\n",
       "      <td>US</td>\n",
       "      <td>343</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1053</td>\n",
       "      <td>1053</td>\n",
       "      <td>1313</td>\n",
       "      <td>1318</td>\n",
       "      <td>US</td>\n",
       "      <td>613</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1915</td>\n",
       "      <td>1915</td>\n",
       "      <td>2110</td>\n",
       "      <td>2133</td>\n",
       "      <td>US</td>\n",
       "      <td>617</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1753</td>\n",
       "      <td>1755</td>\n",
       "      <td>1925</td>\n",
       "      <td>1933</td>\n",
       "      <td>US</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>824</td>\n",
       "      <td>832</td>\n",
       "      <td>1015</td>\n",
       "      <td>1015</td>\n",
       "      <td>US</td>\n",
       "      <td>765</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
       "0  2006      1          11          3      743         745     1024   \n",
       "1  2006      1          11          3     1053        1053     1313   \n",
       "2  2006      1          11          3     1915        1915     2110   \n",
       "3  2006      1          11          3     1753        1755     1925   \n",
       "4  2006      1          11          3      824         832     1015   \n",
       "\n",
       "   CRSArrTime UniqueCarrier  FlightNum  ... TaxiIn  TaxiOut  Cancelled  \\\n",
       "0        1018            US        343  ...     45       13          0   \n",
       "1        1318            US        613  ...     27       19          0   \n",
       "2        2133            US        617  ...      4       11          0   \n",
       "3        1933            US        300  ...     16       10          0   \n",
       "4        1015            US        765  ...     27       12          0   \n",
       "\n",
       "   CancellationCode  Diverted  CarrierDelay WeatherDelay NASDelay  \\\n",
       "0              None         0             0            0        0   \n",
       "1              None         0             0            0        0   \n",
       "2              None         0             0            0        0   \n",
       "3              None         0             0            0        0   \n",
       "4              None         0             0            0        0   \n",
       "\n",
       "   SecurityDelay  LateAircraftDelay  \n",
       "0              0                  0  \n",
       "1              0                  0  \n",
       "2              0                  0  \n",
       "3              0                  0  \n",
       "4              0                  0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"--- Inferred Schema ---\")\n",
    "flights_raw.printSchema()\n",
    "\n",
    "#(using Pandas for better formatting in Jupyter)\n",
    "print(\"--- Data Sample (First 5 rows) ---\")\n",
    "flights_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f57aa",
   "metadata": {},
   "source": [
    "\n",
    "### Data Cleaning:  Delete Forbidden variables\n",
    "\n",
    "\n",
    "Now the first step that we will take is to delete all of the variables whose information would not be available during inference, the \"Forbidden\" variables:\n",
    "\n",
    "* ArrTime\n",
    "* ActualElapsedTime\n",
    "* AirTime\n",
    "* TaxiIn\n",
    "* Diverted\n",
    "* CarrierDelay\n",
    "* WeatherDelay\n",
    "* NASDelay\n",
    "* SecurityDelay\n",
    "* LateAircraftDelay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b032e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Structure after removing forbidden variables ---\n",
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: integer (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiOut: integer (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      "\n",
      "Ensure these variables are not anymore present:\n",
      "\n",
      "All forbidden variables successfully removed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# These variables contain future information known only after landing.\n",
    "forbidden_vars = [\n",
    "    \"ArrTime\",\n",
    "    \"ActualElapsedTime\",\n",
    "    \"AirTime\",\n",
    "    \"TaxiIn\",\n",
    "    \"Diverted\",\n",
    "    \"CarrierDelay\",\n",
    "    \"WeatherDelay\",\n",
    "    \"NASDelay\",\n",
    "    \"SecurityDelay\",\n",
    "    \"LateAircraftDelay\"\n",
    "]\n",
    "\n",
    "# Drop the forbidden columns\n",
    "flights_clean = flights_raw.drop(*forbidden_vars)\n",
    "\n",
    "print(\"--- Structure after removing forbidden variables ---\")\n",
    "flights_clean.printSchema()\n",
    "\n",
    "print(\"Ensure these variables are not anymore present:\\n\")\n",
    "\n",
    "error_found = False\n",
    "for var in forbidden_vars:\n",
    "    if var in flights_clean.columns:\n",
    "        print(f\"ERROR: {var} is still present!\")\n",
    "        error_found = True\n",
    "        \n",
    "if error_found:\n",
    "    print(\"Some forbidden variables are still present. Please check the code.\")\n",
    "else:\n",
    "    print(\"All forbidden variables successfully removed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590120ae",
   "metadata": {},
   "source": [
    "\n",
    "### Data Cleaning: Delete canceled flights and associated columns\n",
    "\n",
    "The first cleaning step we must do is removing all the rows whose flights were cancelled, and delete the columns which express if the flight were canceled, as they won't have useful information anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54e060c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: integer (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiOut: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 150:==========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid flights for training: 14,312,455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flights_clean = flights_clean.filter(\"Cancelled == 0\") \\\n",
    "                            .drop(\"Cancelled\", \"CancellationCode\")\n",
    "                            \n",
    "flights_clean.printSchema()                            \n",
    "print(f\"Total valid flights for training: {flights_clean.count():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb3bff",
   "metadata": {},
   "source": [
    "### Data Cleaning: Null handling\n",
    "\n",
    "Now we will keep assesing the quality of the features that we have available, to verify which techniques of imputation and deletion we should follow. We will also evaluate if we need to transform into categorical some of the variables,  and the consistence showed in their values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30c0e5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Values Analysis ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 153:==========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+----------+-------------+---------+-------+--------------+--------+--------+------+----+--------+-------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|CRSElapsedTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiOut|\n",
      "+----+-----+----------+---------+-------+----------+----------+-------------+---------+-------+--------------+--------+--------+------+----+--------+-------+\n",
      "|0   |0    |0         |0        |0      |0         |0         |0            |0        |0      |727           |33365   |0       |0     |0   |0       |0      |\n",
      "+----+-----+----------+---------+-------+----------+----------+-------------+---------+-------+--------------+--------+--------+------+----+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"--- Missing Values Analysis ---\")\n",
    "# Calculate count of nulls for each column\n",
    "null_counts = flights_clean.select([count(when(col(c).isNull(), c)).alias(c) for c in flights_clean.columns])\n",
    "null_counts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f950a6",
   "metadata": {},
   "source": [
    "The only columns that contain null values are **CRSElapsedTime** and **ArrDelay**, with **727** and **33**,**365** missing values respectively.\n",
    "\n",
    "When dealing with the issue where a lot ot observations have a null value in ArrDelay, it maybe could be consequence of not having filtered the rows whose flight was diverted.It could make sense that  this ones does not have any value setted in the colum ArrDelay, since the flight did not arrive to his original destiny. Thus, we must check if this hypothesis is true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17f95ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  Hypothesis Verification (ArrDelay Nulls vs Diverted) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 156:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Diverted|count|\n",
      "+--------+-----+\n",
      "|       1|33365|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"---  Hypothesis Verification (ArrDelay Nulls vs Diverted) ---\")\n",
    "\n",
    "# We check the raw data to see the relationship between Null ArrDelay and Diverted status\n",
    "flights_raw.filter(\"ArrDelay IS NULL AND Cancelled == 0\") \\\n",
    "           .select(\"ArrDelay\", \"Diverted\", \"Cancelled\") \\\n",
    "           .groupBy(\"Diverted\") \\\n",
    "           .count() \\\n",
    "           .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4637f6",
   "metadata": {},
   "source": [
    "We can confirm our hypothesis since the number of rows which satisfy the condition is equal to the number of nulls we observed earlier in the target variable. Then, we have to process again the flights raw data in order to obtain the clean dataset without nulls in ArrDelay as consequence of flights diverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f113cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Applying Fix (Filtering Diverted flights ---\n",
      "--- Schema check after applying fix: ---\n",
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: integer (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiOut: integer (nullable = true)\n",
      "\n",
      "--- Final Verification (Nulls in ArrDelay) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 159:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|ArrDelay_Null_Count|\n",
      "+-------------------+\n",
      "|                  0|\n",
      "+-------------------+\n",
      "\n",
      "Number of columns in flights_clean: 17\n",
      "Expected number of columns: 17\n",
      "Verification successful: The column count matches the expected reduction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# We must filter out 'Diverted' flights BEFORE dropping the 'Diverted' column.\n",
    "print(\"--- Applying Fix (Filtering Diverted flights ---\")\n",
    "\n",
    "# Re-creating flights_clean with the correct logic:\n",
    "# Filter Cancelled AND Diverted -> Then drop forbidden variables\n",
    "flights_clean = flights_raw.filter(\"Cancelled == 0 AND Diverted == 0\") \\\n",
    "                           .drop(*forbidden_vars) \\\n",
    "                           .drop(\"Cancelled\", \"CancellationCode\")\n",
    "                           \n",
    "print(\"--- Schema check after applying fix: ---\")\n",
    "flights_clean.printSchema()\n",
    "\n",
    "# Checking if 'ArrDelay' still has nulls after the fix.\n",
    "print(\"--- Final Verification (Nulls in ArrDelay) ---\")\n",
    "\n",
    "flights_clean.select(\n",
    "    count(when(col(\"ArrDelay\").isNull(), \"ArrDelay\")).alias(\"ArrDelay_Null_Count\")\n",
    ").show()\n",
    "\n",
    "# Verify if the number of columns in flights_clean matches the expected count\n",
    "# (Raw columns - Forbidden variables - 2 cancellation columns)\n",
    "expected_count = len(flights_raw.columns) - len(forbidden_vars) - 2\n",
    "actual_count = len(flights_clean.columns)\n",
    "\n",
    "print(f\"Number of columns in flights_clean: {actual_count}\")\n",
    "print(f\"Expected number of columns: {expected_count}\")\n",
    "\n",
    "if actual_count == expected_count:\n",
    "    print(\"Verification successful: The column count matches the expected reduction.\")\n",
    "else:\n",
    "    print(\"Verification failed: The column count does not match.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e522fb00",
   "metadata": {},
   "source": [
    "Now that we have fixed the problem of the nulls in our target variable, we have to manage the **nulls of CRSElapsedTime**. So lets impute the nulls, but , how ?. We thinked about calculating the difference between the columns **CrSArrTime and CRSDepTime**, but since we are working with data from flights, this would be difficult since there are differente time zones that would complicate to calcualate this value in a straightforward way. \n",
    "\n",
    "Thus, we have decided to impute this values with the average of the values present in other observation for the flights with the same origin and destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5a0da71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Imputing CRSElapsedTime using Route Average ---\n",
      "--- Final Verification ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|Nulls_After_Smart_Imputation|\n",
      "+----------------------------+\n",
      "|                           0|\n",
      "+----------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 168:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+----------+--------------+\n",
      "|Origin|Dest|CRSDepTime|CRSArrTime|CRSElapsedTime|\n",
      "+------+----+----------+----------+--------------+\n",
      "|   JFK| LAX|      1400|      1709|         369.0|\n",
      "|   JFK| LAX|      1400|      1709|         369.0|\n",
      "|   JFK| LAX|      1400|      1709|         369.0|\n",
      "|   JFK| LAX|      1400|      1709|         369.0|\n",
      "|   JFK| LAX|      1400|      1709|         369.0|\n",
      "+------+----+----------+----------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import avg, col, coalesce, round\n",
    "\n",
    "print(\"--- Imputing CRSElapsedTime using Route Average ---\")\n",
    "\n",
    "# Define the Window: \"Look at all flights sharing the same Origin and Dest\"\n",
    "route_window = Window.partitionBy(\"Origin\", \"Dest\")\n",
    "\n",
    "# Calculate the average scheduled duration for that specific route\n",
    "# We use 'round' to keep it as integer minutes\n",
    "avg_route_duration = round(avg(\"CRSElapsedTime\").over(route_window))\n",
    "\n",
    "# Apply Imputation\n",
    "# If CRSElapsedTime is null, use the Route Average.\n",
    "# If it's still null (e.g., a unique route with only 1 flight that is null), we drop it later.\n",
    "flights_clean = flights_clean.withColumn(\n",
    "    \"CRSElapsedTime\",\n",
    "    coalesce(col(\"CRSElapsedTime\"), avg_route_duration)\n",
    ")\n",
    "\n",
    "# Final Cleanup\n",
    "# Drop any remaining nulls (routes that had NO valid data at all to learn from)\n",
    "flights_clean = flights_clean.dropna(subset=[\"CRSElapsedTime\"])\n",
    "\n",
    "# Verification\n",
    "print(\"--- Final Verification ---\")\n",
    "flights_clean.select(\n",
    "    count(when(col(\"CRSElapsedTime\").isNull(), 1)).alias(\"Nulls_After_Smart_Imputation\")\n",
    ").show()\n",
    "\n",
    "# Show a sample of how it worked (e.g. for a specific route)\n",
    "flights_clean.filter(\"Origin == 'JFK' AND Dest == 'LAX'\") \\\n",
    "             .select(\"Origin\", \"Dest\", \"CRSDepTime\", \"CRSArrTime\", \"CRSElapsedTime\") \\\n",
    "             .limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81463db0",
   "metadata": {},
   "source": [
    "So lets evaluate finally the null count on this dataset before making further analisys and transforamtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "547a0c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 173:==================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+----------+-------------+---------+-------+--------------+--------+--------+------+----+--------+-------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|CRSElapsedTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiOut|\n",
      "+----+-----+----------+---------+-------+----------+----------+-------------+---------+-------+--------------+--------+--------+------+----+--------+-------+\n",
      "|0   |0    |0         |0        |0      |0         |0         |0            |0        |0      |0             |0       |0       |0     |0   |0       |0      |\n",
      "+----+-----+----------+---------+-------+----------+----------+-------------+---------+-------+--------------+--------+--------+------+----+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate count of nulls for each column\n",
    "null_counts = flights_clean.select([count(when(col(c).isNull(), c)).alias(c) for c in flights_clean.columns])\n",
    "null_counts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3998dffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe successfully saved to ../check_point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataframe to a parquet file for future use\n",
    "# flights_clean.write.mode(\"overwrite\").parquet(\"../check_point\")\n",
    "\n",
    "# print(\"Dataframe successfully saved to ../check_point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5419c361",
   "metadata": {},
   "source": [
    "### Data Cleaning: Removal of High-Cardinality Identifiers\n",
    "We proceed to remove specific identifiers that hinder model generalization and introduce noise. FlightNum is discarded as it is a non-ordinal administrative label whose predictive value is effectively redundant, being already better captured by the combination of route, carrier, and schedule information. Similarly we will remove the raw TailNum to prevent the model from overfitting to specific aircraft histories and to avoid the computational overhead associated with processing thousands of unique categorical levels(But this will be done in a few cells, since we need TailNum to join with the plane-data csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7eb07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flights_clean = flights_clean.drop(\"FlightNum\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af6504",
   "metadata": {},
   "source": [
    "### Feature Engineering: Join dataset with other files to enrich features\n",
    "(*exploring additional datasets to try to find additional relevant\n",
    "information*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aedc6d85ae78c40",
   "metadata": {},
   "source": [
    "\n",
    "We have available in the dataset the csv files airports, carriers and  plane-data which we can use to enrich our dataset with more relevant features. We will explore them to asses which new variables we could obtain from joining them to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "682ca993e7cef2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Planes Dataset Schema ---\n",
      "root\n",
      " |-- tailnum: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- issue_date: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- aircraft_type: string (nullable = true)\n",
      " |-- engine_type: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      "\n",
      "--- Planes Dataset Sample (First 5 rows) ---\n",
      "+-------+----+------------+----------+-----+------+-------------+-----------+----+\n",
      "|tailnum|type|manufacturer|issue_date|model|status|aircraft_type|engine_type|year|\n",
      "+-------+----+------------+----------+-----+------+-------------+-----------+----+\n",
      "| N050AA|NULL|        NULL|      NULL| NULL|  NULL|         NULL|       NULL|NULL|\n",
      "| N051AA|NULL|        NULL|      NULL| NULL|  NULL|         NULL|       NULL|NULL|\n",
      "| N052AA|NULL|        NULL|      NULL| NULL|  NULL|         NULL|       NULL|NULL|\n",
      "| N054AA|NULL|        NULL|      NULL| NULL|  NULL|         NULL|       NULL|NULL|\n",
      "| N055AA|NULL|        NULL|      NULL| NULL|  NULL|         NULL|       NULL|NULL|\n",
      "+-------+----+------------+----------+-----+------+-------------+-----------+----+\n",
      "\n",
      "--- Airports Dataset Schema ---\n",
      "root\n",
      " |-- iata: string (nullable = true)\n",
      " |-- airport: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      "\n",
      "--- Airports Dataset Sample (First 5 rows) ---\n",
      "+----+--------------------+----------------+-----+-------+-----------+------------+\n",
      "|iata|             airport|            city|state|country|        lat|        long|\n",
      "+----+--------------------+----------------+-----+-------+-----------+------------+\n",
      "| 00M|            Thigpen |     Bay Springs|   MS|    USA|31.95376472|-89.23450472|\n",
      "| 00R|Livingston Municipal|      Livingston|   TX|    USA|30.68586111|-95.01792778|\n",
      "| 00V|         Meadow Lake|Colorado Springs|   CO|    USA|38.94574889|-104.5698933|\n",
      "| 01G|        Perry-Warsaw|           Perry|   NY|    USA|42.74134667|-78.05208056|\n",
      "| 01J|    Hilliard Airpark|        Hilliard|   FL|    USA| 30.6880125|-81.90594389|\n",
      "+----+--------------------+----------------+-----+-------+-----------+------------+\n",
      "\n",
      "--- Carriers Dataset Schema ---\n",
      "root\n",
      " |-- Code: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n",
      "--- Carriers Dataset Sample (First 5 rows) ---\n",
      "+----+--------------------+\n",
      "|Code|         Description|\n",
      "+----+--------------------+\n",
      "| 02Q|       Titan Airways|\n",
      "| 04Q|  Tradewind Aviation|\n",
      "| 05Q| Comlux Aviation, AG|\n",
      "| 06Q|Master Top Linhas...|\n",
      "| 07Q| Flair Airlines Ltd.|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore additional datasets \n",
    "additional_datasets = {\n",
    "    \"planes\": \"../training_data/flight_data/plane-data.csv\",\n",
    "    \"airports\": \"../training_data/flight_data/airports.csv\",\n",
    "    \"carriers\": \"../training_data/flight_data/carriers.csv\"\n",
    "}\n",
    "for name, path in additional_datasets.items():\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"nullValue\", \"NA\").csv(path)\n",
    "    print(f\"--- {name.capitalize()} Dataset Schema ---\")\n",
    "    df.printSchema()\n",
    "    print(f\"--- {name.capitalize()} Dataset Sample (First 5 rows) ---\")\n",
    "    df.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d04553",
   "metadata": {},
   "source": [
    "We will only use plane-data and airports csv's, since the information available in carriers does not give us useful information for our prediction. We can appreciate that apparantly, plane-data csv have some empty observations. Lets verify that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11b78a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Planes Dataset Null Values Analysis ---\n",
      "+-------+----+------------+----------+-----+------+-------------+-----------+----+\n",
      "|tailnum|type|manufacturer|issue_date|model|status|aircraft_type|engine_type|year|\n",
      "+-------+----+------------+----------+-----+------+-------------+-----------+----+\n",
      "|0      |549 |549         |549       |549  |549   |549          |549        |549 |\n",
      "+-------+----+------------+----------+-----+------+-------------+-----------+----+\n",
      "\n",
      "--- Airports Dataset Null Values Analysis ---\n",
      "+----+-------+----+-----+-------+---+----+\n",
      "|iata|airport|city|state|country|lat|long|\n",
      "+----+-------+----+-----+-------+---+----+\n",
      "|0   |0      |12  |12   |0      |0  |0   |\n",
      "+----+-------+----+-----+-------+---+----+\n",
      "\n",
      "--- Carriers Dataset Null Values Analysis ---\n",
      "+----+-----------+\n",
      "|Code|Description|\n",
      "+----+-----------+\n",
      "|1   |0          |\n",
      "+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verify null observations and columns in additional datasets\n",
    "for name, path in additional_datasets.items():\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"nullValue\", \"NA\").csv(path)\n",
    "    print(f\"--- {name.capitalize()} Dataset Null Values Analysis ---\")\n",
    "    null_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "    null_counts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c1cb7",
   "metadata": {},
   "source": [
    "Now that we have seen that there are some nulls present in the auxiliar tables, we will have to manage that before joining the tables. \n",
    "\n",
    "Thus, We will  first perform a quality check on the auxiliary tables, removing records with missing critical information—such as aircraft manufacturing year or airport geographical coordinates—to prevent propagating noise.\n",
    "\n",
    "We will then execute a series of left joins to incorporate the aircraft's manufacturing year and the geographical context (state and coordinates) for both the origin and destination airports. Finally, we implement a post-join validation step by removing flight records that failed to match with these auxiliary tables. This ensures data integrity and a consistent feature set for the subsequent creation of engineered variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ac741ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Coverage Analysis (Missing Matches) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 14,279,090\n",
      "Flights without Plane metadata: 2,350,705 (16.46%)\n",
      "Flights without Origin metadata: 9,926 (0.07%)\n",
      "Flights without Destination metadata: 9,968 (0.07%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final training set size: 11,910,044\n",
      "Final column count: 26\n",
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: integer (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- CRSElapsedTime: double (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiOut: integer (nullable = true)\n",
      " |-- PlaneYear: string (nullable = true)\n",
      " |-- PlaneManufacturer: string (nullable = true)\n",
      " |-- Origin_City: string (nullable = true)\n",
      " |-- Origin_State: string (nullable = true)\n",
      " |-- Origin_Lat: double (nullable = true)\n",
      " |-- Origin_Long: double (nullable = true)\n",
      " |-- Dest_City: string (nullable = true)\n",
      " |-- Dest_State: string (nullable = true)\n",
      " |-- Dest_Lat: double (nullable = true)\n",
      " |-- Dest_Long: double (nullable = true)\n",
      "\n",
      "--- Enriched Data Sample (First 5 rows) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+----------+-------------+-------+--------------+--------+--------+------+----+--------+-------+---------+-----------------+-----------+------------+-----------+------------+---------+----------+-----------+------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|CRSArrTime|UniqueCarrier|TailNum|CRSElapsedTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiOut|PlaneYear|PlaneManufacturer|Origin_City|Origin_State| Origin_Lat| Origin_Long|Dest_City|Dest_State|   Dest_Lat|   Dest_Long|\n",
      "+----+-----+----------+---------+-------+----------+----------+-------------+-------+--------------+--------+--------+------+----+--------+-------+---------+-----------------+-----------+------------+-----------+------------+---------+----------+-----------+------------+\n",
      "|2006|    1|         2|        1|   1032|      1040|      1200|           XE| N27506|          80.0|       6|      -8|   ABE| CLE|     339|     27|     1999|          EMBRAER|  Allentown|          PA|40.65236278|-75.44040167|Cleveland|        OH|41.41089417|-81.84939667|\n",
      "|2006|    1|         5|        4|   1805|      1815|      1938|           XE| N25504|          83.0|     -18|     -10|   ABE| CLE|     339|      6|     1999|          EMBRAER|  Allentown|          PA|40.65236278|-75.44040167|Cleveland|        OH|41.41089417|-81.84939667|\n",
      "|2006|    1|        11|        3|   1352|      1405|      1525|           XE| N16510|          80.0|     -23|     -13|   ABE| CLE|     339|     10|     2000|          EMBRAER|  Allentown|          PA|40.65236278|-75.44040167|Cleveland|        OH|41.41089417|-81.84939667|\n",
      "|2006|    1|        26|        4|   1806|      1815|      1938|           XE| N16501|          83.0|     -17|      -9|   ABE| CLE|     339|     11|     1999|          EMBRAER|  Allentown|          PA|40.65236278|-75.44040167|Cleveland|        OH|41.41089417|-81.84939667|\n",
      "|2006|    1|        13|        5|   1416|      1405|      1525|           XE| N25504|          80.0|       9|      11|   ABE| CLE|     339|     14|     1999|          EMBRAER|  Allentown|          PA|40.65236278|-75.44040167|Cleveland|        OH|41.41089417|-81.84939667|\n",
      "+----+-----+----------+---------+-------+----------+----------+-------------+-------+--------------+--------+--------+------+----+--------+-------+---------+-----------------+-----------+------------+-----------+------------+---------+----------+-----------+------------+\n",
      "\n",
      "--- Null Values Analysis after Enrichment ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+----------+-------------+-------+--------------+--------+--------+------+----+--------+-------+---------+-----------------+-----------+------------+----------+-----------+---------+----------+--------+---------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|CRSArrTime|UniqueCarrier|TailNum|CRSElapsedTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiOut|PlaneYear|PlaneManufacturer|Origin_City|Origin_State|Origin_Lat|Origin_Long|Dest_City|Dest_State|Dest_Lat|Dest_Long|\n",
      "+----+-----+----------+---------+-------+----------+----------+-------------+-------+--------------+--------+--------+------+----+--------+-------+---------+-----------------+-----------+------------+----------+-----------+---------+----------+--------+---------+\n",
      "|0   |0    |0         |0        |0      |0         |0         |0            |0      |0             |0       |0       |0     |0   |0       |0      |0        |0                |0          |0           |0         |0          |0        |0         |0       |0        |\n",
      "+----+-----+----------+---------+-------+----------+----------+-------------+-------+--------------+--------+--------+------+----+--------+-------+---------+-----------------+-----------+------------+----------+-----------+---------+----------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, broadcast\n",
    "\n",
    "# load dataframes \n",
    "planes_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"nullValue\", \"NA\").csv(\"../training_data/flight_data/plane-data.csv\")\n",
    "airports_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"nullValue\", \"NA\").csv(\"../training_data/flight_data/airports.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# 1. Pre-cleaning \n",
    "# ----------------------------------------------------------\n",
    "planes_clean = planes_df.dropna(subset=[\"year\", \"manufacturer\"]) \\\n",
    "                        .select(col(\"tailnum\").alias(\"TailNum_Ref\"), \n",
    "                                col(\"year\").alias(\"PlaneYear\"),\n",
    "                                col(\"manufacturer\").alias(\"PlaneManufacturer\"))\n",
    "\n",
    "airports_clean = airports_df.dropna(subset=[\"city\", \"state\"]) \\\n",
    "                            .select(col(\"iata\").alias(\"iata_ref\"), \n",
    "                                    col(\"city\"), col(\"state\"), \n",
    "                                    col(\"lat\"), col(\"long\"))\n",
    "\n",
    "# 2. Executing Joins\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Plane data\n",
    "enriched_df = flights_clean.join(broadcast(planes_clean), \n",
    "                                 flights_clean.TailNum == planes_clean.TailNum_Ref, \"left\")\n",
    "\n",
    "# Origin Airport data\n",
    "enriched_df = enriched_df.join(\n",
    "    broadcast(airports_clean.select(col(\"iata_ref\").alias(\"O_ref\"), \n",
    "                                    col(\"city\").alias(\"Origin_City\"),\n",
    "                                    col(\"state\").alias(\"Origin_State\"), \n",
    "                                    col(\"lat\").alias(\"Origin_Lat\"), \n",
    "                                    col(\"long\").alias(\"Origin_Long\"))),\n",
    "    col(\"Origin\") == col(\"O_ref\"), \"left\"\n",
    ")\n",
    "\n",
    "# Destination Airport data\n",
    "enriched_df = enriched_df.join(\n",
    "    broadcast(airports_clean.select(col(\"iata_ref\").alias(\"D_ref\"), \n",
    "                                    col(\"city\").alias(\"Dest_City\"),\n",
    "                                    col(\"state\").alias(\"Dest_State\"), \n",
    "                                    col(\"lat\").alias(\"Dest_Lat\"), \n",
    "                                    col(\"long\").alias(\"Dest_Long\"))),\n",
    "    col(\"Dest\") == col(\"D_ref\"), \"left\"\n",
    ")\n",
    "\n",
    "# 3. Data Loss Verification (The Diagnostic)\n",
    "# ----------------------------------------------------------\n",
    "print(\"--- Data Coverage Analysis (Missing Matches) ---\")\n",
    "\n",
    "total_flights = enriched_df.count()\n",
    "\n",
    "# Count nulls for each source\n",
    "stats = enriched_df.select(\n",
    "    count(when(col(\"PlaneYear\").isNull(), 1)).alias(\"Missing_Plane_Info\"),\n",
    "    count(when(col(\"Origin_City\").isNull(), 1)).alias(\"Missing_Origin_Info\"),\n",
    "    count(when(col(\"Dest_City\").isNull(), 1)).alias(\"Missing_Dest_Info\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Total Rows: {total_flights:,}\")\n",
    "print(f\"Flights without Plane metadata: {stats['Missing_Plane_Info']:,} ({stats['Missing_Plane_Info']/total_flights:.2%})\")\n",
    "print(f\"Flights without Origin metadata: {stats['Missing_Origin_Info']:,} ({stats['Missing_Origin_Info']/total_flights:.2%})\")\n",
    "print(f\"Flights without Destination metadata: {stats['Missing_Dest_Info']:,} ({stats['Missing_Dest_Info']/total_flights:.2%})\")\n",
    "\n",
    "# 4. Final Cleanup (Turning Left Join into \"Inner Join\" logic)\n",
    "# ----------------------------------------------------------\n",
    "enriched_df = enriched_df.dropna(subset=[\"PlaneYear\", \"Origin_City\", \"Dest_City\"])\n",
    "enriched_df = enriched_df.drop(\"TailNum_Ref\", \"O_ref\", \"D_ref\")\n",
    "\n",
    "print(f\"\\nFinal training set size: {enriched_df.count():,}\")\n",
    "\n",
    "print(f\"Final column count: {len(enriched_df.columns)}\")\n",
    "enriched_df.printSchema()\n",
    "\n",
    "print(\"--- Enriched Data Sample (First 5 rows) ---\")\n",
    "enriched_df.limit(5).show()\n",
    "\n",
    "# 5. Null value analysis after enrichment\n",
    "print(\"--- Null Values Analysis after Enrichment ---\")\n",
    "null_counts = enriched_df.select([count(when(col(c).isNull(), c)).alias(c) for c in enriched_df.columns])\n",
    "null_counts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f153bcc",
   "metadata": {},
   "source": [
    "### Feature Engineering: Agreggation and mixing of columns in order to create new columns that could be useful \n",
    "\n",
    "With the external datasets successfully integrated, we now transform raw data into more meaningful predictors for the model. We calculate the aircraft's age—derived from the flight year and manufacture year—to capture potential mechanical reliability trends. To account for daily operational cycles and peak congestion, we extract the scheduled departure hour from the timestamp. Additionally, we create a binary indicator to distinguish weekend traffic dynamics from business-day patterns. To conclude this stage, we drop the raw manufacture year and aircraft identifiers, refining our feature space to focus on generalized signals rather than specific registrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d89d5f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New Features Created with Spark 4.0 Safety ---\n",
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: integer (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- CRSElapsedTime: double (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- DepDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiOut: integer (nullable = true)\n",
      " |-- PlaneManufacturer: string (nullable = true)\n",
      " |-- Origin_City: string (nullable = true)\n",
      " |-- Origin_State: string (nullable = true)\n",
      " |-- Origin_Lat: double (nullable = true)\n",
      " |-- Origin_Long: double (nullable = true)\n",
      " |-- Dest_City: string (nullable = true)\n",
      " |-- Dest_State: string (nullable = true)\n",
      " |-- Dest_Lat: double (nullable = true)\n",
      " |-- Dest_Long: double (nullable = true)\n",
      " |-- PlaneAge: integer (nullable = true)\n",
      " |-- DepHour: integer (nullable = true)\n",
      " |-- IsWeekend: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 297:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-------+---------+\n",
      "|Year|PlaneAge|DepHour|IsWeekend|\n",
      "+----+--------+-------+---------+\n",
      "|2006|       7|     10|        0|\n",
      "|2006|       7|     18|        0|\n",
      "|2006|       6|     14|        0|\n",
      "|2006|       7|     18|        0|\n",
      "|2006|       7|     14|        0|\n",
      "+----+--------+-------+---------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, floor, expr\n",
    "\n",
    "# 1. PlaneAge: Usamos try_cast para que los \"None\" pasen a ser NULL silenciosamente\n",
    "enriched_df = enriched_df.withColumn(\n",
    "    \"PlaneAge\", \n",
    "    (col(\"Year\") - expr(\"try_cast(PlaneYear AS INT)\")).cast(\"int\")\n",
    ")\n",
    "\n",
    "# 2. DepHour: Aplicamos try_cast también por seguridad si CRSDepTime viene sucio\n",
    "enriched_df = enriched_df.withColumn(\n",
    "    \"DepHour\", \n",
    "    floor(expr(\"try_cast(CRSDepTime AS INT)\") / 100).cast(\"int\")\n",
    ")\n",
    "\n",
    "# 3. IsWeekend: Binary flag (DayOfWeek suele ser INT, pero por si acaso...)\n",
    "enriched_df = enriched_df.withColumn(\n",
    "    \"IsWeekend\",\n",
    "    (expr(\"try_cast(DayOfWeek AS INT)\") > 5).cast(\"int\")\n",
    ")\n",
    "\n",
    "# 4. Final Cleanup\n",
    "enriched_df = enriched_df.drop(\"TailNum\", \"PlaneYear\")\n",
    "\n",
    "print(\"--- New Features Created with Spark 4.0 Safety ---\")\n",
    "enriched_df.printSchema()\n",
    "enriched_df.select(\"Year\", \"PlaneAge\", \"DepHour\", \"IsWeekend\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f510fb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataframe successfully reordered ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 302:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+---------+-------+-------------+--------+-----------------+--------+----------+----------+--------------+------+-----------+------------+-----------+------------+----+---------+----------+-----------+------------+-------+--------+-------+--------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|IsWeekend|DepHour|UniqueCarrier|Distance|PlaneManufacturer|PlaneAge|CRSDepTime|CRSArrTime|CRSElapsedTime|Origin|Origin_City|Origin_State| Origin_Lat| Origin_Long|Dest|Dest_City|Dest_State|   Dest_Lat|   Dest_Long|DepTime|DepDelay|TaxiOut|ArrDelay|\n",
      "+----+-----+----------+---------+---------+-------+-------------+--------+-----------------+--------+----------+----------+--------------+------+-----------+------------+-----------+------------+----+---------+----------+-----------+------------+-------+--------+-------+--------+\n",
      "|2006|    1|         2|        1|        0|     10|           XE|     339|          EMBRAER|       7|      1040|      1200|          80.0|   ABE|  Allentown|          PA|40.65236278|-75.44040167| CLE|Cleveland|        OH|41.41089417|-81.84939667|   1032|      -8|     27|       6|\n",
      "|2006|    1|         5|        4|        0|     18|           XE|     339|          EMBRAER|       7|      1815|      1938|          83.0|   ABE|  Allentown|          PA|40.65236278|-75.44040167| CLE|Cleveland|        OH|41.41089417|-81.84939667|   1805|     -10|      6|     -18|\n",
      "|2006|    1|        11|        3|        0|     14|           XE|     339|          EMBRAER|       6|      1405|      1525|          80.0|   ABE|  Allentown|          PA|40.65236278|-75.44040167| CLE|Cleveland|        OH|41.41089417|-81.84939667|   1352|     -13|     10|     -23|\n",
      "|2006|    1|        26|        4|        0|     18|           XE|     339|          EMBRAER|       7|      1815|      1938|          83.0|   ABE|  Allentown|          PA|40.65236278|-75.44040167| CLE|Cleveland|        OH|41.41089417|-81.84939667|   1806|      -9|     11|     -17|\n",
      "|2006|    1|        13|        5|        0|     14|           XE|     339|          EMBRAER|       7|      1405|      1525|          80.0|   ABE|  Allentown|          PA|40.65236278|-75.44040167| CLE|Cleveland|        OH|41.41089417|-81.84939667|   1416|      11|     14|       9|\n",
      "+----+-----+----------+---------+---------+-------+-------------+--------+-----------------+--------+----------+----------+--------------+------+-----------+------------+-----------+------------+----+---------+----------+-----------+------------+-------+--------+-------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Column Reordering\n",
    "# ==========================================================\n",
    "\n",
    "# Grouping columns by logic: Temporal, Operational, Geographic, and Metrics\n",
    "ordered_columns = [\n",
    "    # 1. Temporal Features\n",
    "    \"Year\", \"Month\", \"DayofMonth\", \"DayOfWeek\", \"IsWeekend\", \"DepHour\",\n",
    "    \n",
    "    # 2. Flight & Aircraft Information\n",
    "    \"UniqueCarrier\", \"Distance\", \"PlaneManufacturer\", \"PlaneAge\",\n",
    "    \n",
    "    # 3. Schedule Information\n",
    "    \"CRSDepTime\", \"CRSArrTime\", \"CRSElapsedTime\",\n",
    "    \n",
    "    # 4. Origin Geography\n",
    "    \"Origin\", \"Origin_City\", \"Origin_State\", \"Origin_Lat\", \"Origin_Long\",\n",
    "    \n",
    "    # 5. Destination Geography\n",
    "    \"Dest\", \"Dest_City\", \"Dest_State\", \"Dest_Lat\", \"Dest_Long\",\n",
    "    \n",
    "    # 6. Real-time Metrics and Target Variable\n",
    "    \"DepTime\", \"DepDelay\", \"TaxiOut\", \"ArrDelay\"\n",
    "]\n",
    "\n",
    "# Apply the selection\n",
    "enriched_df = enriched_df.select(*ordered_columns)\n",
    "\n",
    "print(\"--- Dataframe successfully reordered ---\")\n",
    "enriched_df.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207da32",
   "metadata": {},
   "source": [
    "# CHECKPOINT: DELETE BEFORE SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcd155ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "enriched_df.write.mode(\"overwrite\").parquet(\"../check_point_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98e6b3",
   "metadata": {},
   "source": [
    "# Punto de Carga\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Re-cargas (esto crea un nuevo punto de partida limpio)\n",
    "enriched_df = spark.read.parquet(\"../check_point_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0559303f",
   "metadata": {},
   "source": [
    "### EDA and statistical analysis over these features\n",
    "*(Proper exploratory data analysis (possibly including univariate and/or multivariate\n",
    "analysis) to better understand the input data and provide robust criteria for variable\n",
    "selection.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2728c5",
   "metadata": {},
   "source": [
    "### Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9967e745",
   "metadata": {},
   "source": [
    "### PCA ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6331a093214c8c7d",
   "metadata": {},
   "source": [
    "## Code used to train, test and save the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bfcbb6",
   "metadata": {},
   "source": [
    "### Scaling of values ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372079fc",
   "metadata": {},
   "source": [
    "### Definition of models to employ and metrics to use \n",
    "* *Select more than one valid machine learning algorithm for building the model.*\n",
    "* *Consider more than one possible model performance metric and explain the criteria for\n",
    "selecting the most appropriate*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ba2b3",
   "metadata": {},
   "source": [
    "### Cross-Validation loop to validate models with 80/20\n",
    "* *Use cross-validation techniques to select the best model*\n",
    "* *Perform model hyper-parameter tuning*\n",
    "* *Use the full capacities of Spark’s MLlib*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0243d2e",
   "metadata": {},
   "source": [
    "### Selection and saving the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24741b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
